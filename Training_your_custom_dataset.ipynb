{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training your custom dataset.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMjbI1fyi3V6EXOK/RlBtDe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YMMM98/Mask-R-CNN-Training-to-deployement-in-Colab/blob/main/Training_your_custom_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# We clone the original Mask R-CNN repo first\n"
      ],
      "metadata": {
        "id": "NlNaegKGt5FC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZEZYgswtrie"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/matterport/Mask_RCNN"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checking GPU and installing dependencies\n"
      ],
      "metadata": {
        "id": "2VfokSQOuEOh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Don't forget to switch to use gpu.     Runtime -> Change runtime -> GPU"
      ],
      "metadata": {
        "id": "jcsNMkWIuK-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "jRru8bGVuJN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell \n",
        "pip install tensorflow==1.13.1 keras==2.0.8 \n",
        "pip install h5py==2.10.0\n",
        "pip install tensorflow-gpu==1.13.1"
      ],
      "metadata": {
        "id": "oG8b4PeKuJRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.test.is_gpu_available(cuda_only=False, min_cuda_compute_capability=None)\n",
        "#we need true"
      ],
      "metadata": {
        "id": "5MpQ7jOCuJVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up the config file"
      ],
      "metadata": {
        "id": "QiSSbEjuu6IA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import numpy as np\n",
        "import time\n",
        "from PIL import Image, ImageDraw"
      ],
      "metadata": {
        "id": "JIs8tlLjuu4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the ROOT_DIR variable to the root directory of the Mask_RCNN git repo\n",
        "ROOT_DIR = '/content/Mask_RCNN'\n",
        "assert os.path.exists(ROOT_DIR)\n",
        "\n",
        "# Import mrcnn libraries\n",
        "sys.path.append(ROOT_DIR) \n",
        "from mrcnn.config import Config\n",
        "import mrcnn.utils as utils\n",
        "from mrcnn import visualize\n",
        "import mrcnn.model as modellib"
      ],
      "metadata": {
        "id": "RH6yPcpovEXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory to save logs and trained model\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")"
      ],
      "metadata": {
        "id": "xwXLk4x9vEaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can download your own pre-trained model and continue training or use the COCO or ImageNet weights"
      ],
      "metadata": {
        "id": "UWllJ0Biv7VR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "gdown https://drive.google.com/uc?id=1Pw5iDiIFc6_HL9E6kXU0fkw-wVybqbNw\n",
        "#I download my own pre-trained model from google drive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oq1qayr-wS6T",
        "outputId": "08407314-a8ea-44c3-e390-b5b4102829f1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Pw5iDiIFc6_HL9E6kXU0fkw-wVybqbNw\n",
            "To: /content/mask_rcnn_rod101_0004.h5\n",
            "100% 256M/256M [00:05<00:00, 48.4MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Or Download COCO weights\n",
        "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
        "if not os.path.exists(COCO_MODEL_PATH):\n",
        "   utils.download_trained_weights(COCO_MODEL_PATH)"
      ],
      "metadata": {
        "id": "oRZtCvYwvEcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class morsnowConfig(Config):\n",
        "    \"\"\"Configuration for training on the Rod dataset.\n",
        "    Derives from the base Config class and overrides values specific\n",
        "    to ours.\n",
        "    \"\"\"\n",
        "    # Config name\n",
        "    NAME = \"Rod101\"\n",
        "\n",
        "    # Train on 1 GPU and 1 image per GPU. Batch size is 1 (GPUs * images/GPU).\n",
        "    GPU_COUNT = 1\n",
        "    # Number of images to train with on each GPU. A 12GB GPU can typically\n",
        "    # handle 2 images of 1024x1024px.\n",
        "    # Adjust based on the GPU memory and image sizes you got in colab.\n",
        "    IMAGES_PER_GPU = 1\n",
        "\n",
        "    # Number of classes (including background)\n",
        "    NUM_CLASSES = 1 + 1  # background + 1 (Snow Rod)\n",
        "\n",
        "    # I chose 1024x1024 as most of our pictures are 1200x1600\n",
        "    IMAGE_MIN_DIM = 1024\n",
        "    IMAGE_MAX_DIM = 1024\n",
        "\n",
        "    # learning rate and momentum\n",
        "    LEARNING_RATE = 0.001\n",
        "    LEARNING_MOMENTUM = 0.9    \n",
        "\n",
        "    # Weight decay regularization\n",
        "    WEIGHT_DECAY = 0.0001\n",
        "\n",
        "    # Number of training steps per epoch\n",
        "    # This doesn't need to match the size of the training set. Tensorboard\n",
        "    # updates are saved at the end of each epoch, so setting this to a\n",
        "    # smaller number means getting more frequent TensorBoard updates.\n",
        "    # Validation stats are also calculated at each epoch end and they\n",
        "    # might take a while, so don't set this too small to avoid spending\n",
        "    # a lot of time on validation stats.\n",
        "    STEPS_PER_EPOCH = 45\n",
        "\n",
        "    # This is how often validation is run. \n",
        "    # the bigger, the better the accuracy and the slower the training\n",
        "    VALIDATION_STEPS = 5\n",
        "    \n",
        "    # the availabe ones for now are resnet50 and resnet101 in this repo.\n",
        "    BACKBONE = 'resnet101'\n",
        "\n",
        "    # Other hyperparameters, no need to modify them as the performance is already good enough\n",
        "    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)\n",
        "    TRAIN_ROIS_PER_IMAGE = 32\n",
        "    MAX_GT_INSTANCES = 50 \n",
        "    POST_NMS_ROIS_INFERENCE = 500 \n",
        "    POST_NMS_ROIS_TRAINING = 1000 \n",
        "    \n",
        "    #Check Mask_RCNN/mrcnn/config.py for more parameters to tune.\n",
        "\n",
        "config = morsnowConfig()\n",
        "config.display()"
      ],
      "metadata": {
        "id": "sTSdzmJbvEeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-processing the Dataset\n"
      ],
      "metadata": {
        "id": "cxgTVidtzOzd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We upload our zip file, that contains 4 things :  \n",
        "\n",
        "1.  Training folder\n",
        "2.  Validation folder\n",
        "3.  Annotations for training  (Coco Format)\n",
        "4.  Annotations for Validation\n",
        "\n",
        "i used Makesense.ai for the annotation, but VGG annotator is good too."
      ],
      "metadata": {
        "id": "2sYWkCxczkjz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/dataset.zip"
      ],
      "metadata": {
        "id": "LTRYgEehvEgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helper class to prepare the dataset"
      ],
      "metadata": {
        "id": "jQLWtVl90Gb7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CocoLikeDataset(utils.Dataset):\n",
        "    \"\"\" See http://cocodataset.org/#home for more information. \"\"\"\n",
        "    def load_data(self, annotation_json, images_dir):\n",
        "        \n",
        "        \"\"\" Load the coco-format dataset from json\n",
        "        Args:\n",
        "            annotation_json: The path to the coco annotations json file\n",
        "            images_dir: The directory holding the images referred to by the json file\n",
        "        \"\"\"\n",
        "        \n",
        "        # Load json from file\n",
        "        json_file = open(annotation_json)\n",
        "        coco_json = json.load(json_file)\n",
        "        json_file.close()\n",
        "        \n",
        "        # Add the class names using the base method from utils.Dataset\n",
        "        source_name = \"coco_like\"\n",
        "        for category in coco_json['categories']:\n",
        "            class_id = category['id']\n",
        "            class_name = category['name']\n",
        "            if class_id < 1:\n",
        "                print('Error: Class id for \"{}\" cannot be less than one. (0 is reserved for the background)'.format(class_name))\n",
        "                return\n",
        "            \n",
        "            self.add_class(source_name, class_id, class_name)\n",
        "        \n",
        "        # Get all annotations\n",
        "        annotations = {}\n",
        "        for annotation in coco_json['annotations']:\n",
        "            image_id = annotation['image_id']\n",
        "            if image_id not in annotations:\n",
        "                annotations[image_id] = []\n",
        "            annotations[image_id].append(annotation)\n",
        "        \n",
        "        # Get all images and add them to the dataset\n",
        "        seen_images = {}\n",
        "        for image in coco_json['images']:\n",
        "            image_id = image['id']\n",
        "            if image_id in seen_images:\n",
        "                print(\"Warning: Skipping duplicate image id: {}\".format(image))\n",
        "            else:\n",
        "                seen_images[image_id] = image\n",
        "                try:\n",
        "                    image_file_name = image['file_name']\n",
        "                    image_width = image['width']\n",
        "                    image_height = image['height']\n",
        "                except KeyError as key:\n",
        "                    print(\"Warning: Skipping image (id: {}) with missing key: {}\".format(image_id, key))\n",
        "                \n",
        "                image_path = os.path.abspath(os.path.join(images_dir, image_file_name))\n",
        "                image_annotations = annotations[image_id]\n",
        "                \n",
        "                # Add the image using the base method from utils.Dataset\n",
        "                self.add_image(\n",
        "                    source=source_name,\n",
        "                    image_id=image_id,\n",
        "                    path=image_path,\n",
        "                    width=image_width,\n",
        "                    height=image_height,\n",
        "                    annotations=image_annotations\n",
        "                )\n",
        "                \n",
        "    def load_mask(self, image_id):\n",
        "        \"\"\" Load instance masks for the given image.\n",
        "        MaskRCNN expects masks in the form of a bitmap [height, width, instances].\n",
        "        Args:\n",
        "            image_id: The id of the image to load masks for\n",
        "        Returns:\n",
        "            masks: A bool array of shape [height, width, instance count] with\n",
        "                one mask per instance.\n",
        "            class_ids: a 1D array of class IDs of the instance masks.\n",
        "        \"\"\"\n",
        "        image_info = self.image_info[image_id]\n",
        "        annotations = image_info['annotations']\n",
        "        instance_masks = []\n",
        "        class_ids = []\n",
        "        \n",
        "        for annotation in annotations:\n",
        "            class_id = annotation['category_id']\n",
        "            mask = Image.new('1', (image_info['width'], image_info['height']))\n",
        "            mask_draw = ImageDraw.ImageDraw(mask, '1')\n",
        "            for segmentation in annotation['segmentation']:\n",
        "                mask_draw.polygon(segmentation, fill=1)\n",
        "                bool_array = np.array(mask) > 0\n",
        "                instance_masks.append(bool_array)\n",
        "                class_ids.append(class_id)\n",
        "\n",
        "        mask = np.dstack(instance_masks)\n",
        "        class_ids = np.array(class_ids, dtype=np.int32)\n",
        "        \n",
        "        return mask, class_ids"
      ],
      "metadata": {
        "id": "zm-r5ebyzSde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train = CocoLikeDataset()\n",
        "dataset_train.load_data( '/content/cocoTRAIN.json' , '/content/Train')\n",
        "dataset_train.prepare()\n",
        "\n",
        "dataset_val = CocoLikeDataset()\n",
        "dataset_val.load_data('/content/cocoVAL.json', '/content/val')\n",
        "dataset_val.prepare()"
      ],
      "metadata": {
        "id": "fNsyilvtzSfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizing the dataset"
      ],
      "metadata": {
        "id": "Y9RPFjhu0r0t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset_train\n",
        "image_ids = np.random.choice(dataset.image_ids, 4)\n",
        "for image_id in image_ids:\n",
        "    image = dataset.load_image(image_id)\n",
        "    mask, class_ids = dataset.load_mask(image_id)\n",
        "    visualize.display_top_masks(image, mask, class_ids, dataset.class_names)"
      ],
      "metadata": {
        "id": "L-DpqleDzShP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "o-edI-A505NE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model in training mode\n",
        "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
        "                          model_dir=MODEL_DIR)"
      ],
      "metadata": {
        "id": "ay9BLGf802zT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you downloaded the coco weights, run this"
      ],
      "metadata": {
        "id": "uMm7qq4v1FX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Which weights to start with?\n",
        "init_with = \"coco\"  # imagenet, coco, or last if we upload our own weights\n",
        "\n",
        "if init_with == \"imagenet\":\n",
        "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
        "elif init_with == \"coco\":\n",
        "    # Load weights trained on MS COCO, but skip layers that\n",
        "    # are different due to the different number of classes\n",
        "    # See README for instructions to download the COCO weights\n",
        "    model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
        "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
        "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
        "elif init_with == \"last\":\n",
        "    # Load the last model you trained and continue training\n",
        "    model.load_weights(model.find_last(), by_name=True)"
      ],
      "metadata": {
        "id": "k4QVJBKJ021T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the head branches Passing layers=\"heads\" freezes all layers except the head layers. You can also pass a regular expression to select\n",
        "# which layers to train by name pattern.\n",
        "# or layers = \"all\" if you want to fine-tune all layers\n",
        "start_train = time.time()\n",
        "\n",
        "model.train(dataset_train, dataset_val, \n",
        "            learning_rate=config.LEARNING_RATE,\n",
        "            epochs=3, \n",
        "            layers='heads')\n",
        "\n",
        "end_train = time.time()\n",
        "minutes = round((end_train - start_train) / 60, 2)\n",
        "print(f'Training took {minutes} minutes')"
      ],
      "metadata": {
        "id": "qUL8ZJL0023l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inspecting the results\n"
      ],
      "metadata": {
        "id": "P_ZxIbZY11LJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use tensorboad to check the loss"
      ],
      "metadata": {
        "id": "Qu5RAeAX19_g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard.notebook\n",
        "#%reload_ext tensorboard.notebook"
      ],
      "metadata": {
        "id": "VAl_OTWg025m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "event = /content/Mask_RCNN/logs/rod10120220509T2129\n",
        "# put the path that leads to the directory that has the tf.events file, should be in mrcnn> logs > NameOfyourConfig"
      ],
      "metadata": {
        "id": "Y3aUaFjy2D53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir event"
      ],
      "metadata": {
        "id": "m24-40xc027w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  I still need to add mAP evaluation, weights histogram, precision/recall,..."
      ],
      "metadata": {
        "id": "r5JWeNt02opB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "C8t9Ac7f2nSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing the model"
      ],
      "metadata": {
        "id": "mQvb9bGO3Asn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class InferenceConfig(morsnowConfig):\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "    IMAGE_MIN_DIM = 1024\n",
        "    IMAGE_MAX_DIM = 1024\n",
        "\n",
        "    #minimum confidence\n",
        "    DETECTION_MIN_CONFIDENCE = 0.8\n",
        "    \n",
        "\n",
        "inference_config = InferenceConfig()"
      ],
      "metadata": {
        "id": "oMYcgCE43FWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recreate the model in inference mode"
      ],
      "metadata": {
        "id": "ZKGQUs063Y6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = modellib.MaskRCNN(mode=\"inference\", \n",
        "                          config=inference_config,\n",
        "                          model_dir=MODEL_DIR)"
      ],
      "metadata": {
        "id": "sTvXqeUP3FY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Give the path to saved weights"
      ],
      "metadata": {
        "id": "fhKfIG5a3jC9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get path to saved weights \n",
        "# Either set a specific path or find last trained weights\n",
        "# model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\n",
        "model_path = model.find_last()\n",
        "model.load_weights(model_path, by_name=True)"
      ],
      "metadata": {
        "id": "0SvGZlHu3i2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Or use your downloanded pre-trained weights"
      ],
      "metadata": {
        "id": "Mj5YsbDO3w97"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = '/content/mask_rcnn_rod101_0004.h5'\n",
        "model.load_weights(model_path, by_name=True)"
      ],
      "metadata": {
        "id": "wmAQY4O_3wzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload some images to test."
      ],
      "metadata": {
        "id": "Gf687VvR4Krt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/test.zip"
      ],
      "metadata": {
        "id": "5jCHIni-3FbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#background + our classes\n",
        "class_names = ['BG','Rod']"
      ],
      "metadata": {
        "id": "4rHwKYKw43Yt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run prediction on all your folder images"
      ],
      "metadata": {
        "id": "aIxk82nX49WD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import skimage\n",
        "real_test_dir = '/content/Real_test'\n",
        "image_paths = []\n",
        "for filename in os.listdir(real_test_dir):\n",
        "    if os.path.splitext(filename)[1].lower() in ['.png', '.jpg', '.jpeg']:\n",
        "        image_paths.append(os.path.join(real_test_dir, filename))\n",
        "\n",
        "for image_path in image_paths:\n",
        "    img = skimage.io.imread(image_path)\n",
        "    img_arr = np.array(img)\n",
        "    results = model.detect([img_arr], verbose=1)\n",
        "    r = results[0]\n",
        "    visualize.display_instances(img, r['rois'], r['masks'], r['class_ids'], \n",
        "                                class_names, r['scores'], figsize=(5,5))"
      ],
      "metadata": {
        "id": "fob1-7jR44h5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run prediction on one image"
      ],
      "metadata": {
        "id": "0YLEbUD75Ekn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/test.jpg'\n",
        "image = skimage.io.imread(path)\n",
        "\n",
        "# Run detection\n",
        "results = model.detect([image], verbose=0)\n",
        "\n",
        "# Visualize results\n",
        "r = results[0]\n",
        "visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
        "                            class_names, r['scores'])"
      ],
      "metadata": {
        "id": "sirwXBN244pv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}